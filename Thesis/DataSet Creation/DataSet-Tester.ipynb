{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afc9885",
   "metadata": {
    "id": "5afc9885",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Header\n",
    "\n",
    "text\n",
    "\n",
    "**Note:** text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "###\n",
    "lib_path = [r'C:\\Users\\ikahbasi\\OneDrive\\Applications\\GitHub\\SeisRoutine',\n",
    "            r'C:\\Users\\ikahb\\OneDrive\\Applications\\GitHub\\SeisRoutine']\n",
    "for path in lib_path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369409d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SeisRoutine.catalog as src\n",
    "import SeisRoutine.waveform as srw\n",
    "import SeisRoutine.config as srconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5a03f",
   "metadata": {
    "id": "a5d5a03f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff73a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# List all installed packages and their versions\n",
    "installed_packages = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "\n",
    "for package in sorted(installed_packages.keys()):\n",
    "    version = installed_packages[package]\n",
    "    print(f\"{package}=={version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d76abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ffffa",
   "metadata": {},
   "source": [
    "#### Loading configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de598521",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cfg = srconf.load_config('0-init-cfg.yml')\n",
    "cfg = srconf.load_config(init_cfg.target_config_filename)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba93ee",
   "metadata": {
    "id": "11ba93ee",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading the dataset\n",
    "\n",
    "Now that the dataset conversion is finished, we can check it by simply loading it. Here we load the dataset, print the metadata and visualize the first waveform together with the annotated pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e21b9",
   "metadata": {
    "id": "517e21b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_path = Path(cfg.dataset_test.path.dataset)\n",
    "# base_path = Path(r\"C:\\Users\\ikahb\\Downloads\\Kaki-Dataset-All_1403-12-04\")\n",
    "data = sbd.WaveformDataset(base_path, sampling_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc028665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata['split'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22a167",
   "metadata": {
    "id": "bd22a167",
    "outputId": "73f9f276-334b-4c71-a8d1-7b55ad7bc9ab",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training examples:\", len(data.train()))\n",
    "print(\"Development examples:\", len(data.dev()))\n",
    "print(\"Test examples:\", len(data.test()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d4bce",
   "metadata": {
    "id": "3e4d4bce",
    "outputId": "56570c19-a678-4e6a-89b1-df8087434807",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = [key for key in data.metadata.keys() if 'arrival' in key]\n",
    "data.metadata[targets]\n",
    "# data.metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmap(phase_hint):\n",
    "    c = {'Pg': 'r', 'Sg': 'b', 'AML': 'c'}\n",
    "    return c.get(phase_hint, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851d1a5",
   "metadata": {
    "id": "3851d1a5",
    "outputId": "876eb18a-bd36-4be6-fd7d-13296fea9cd3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "range_ii = [10, 20]\n",
    "for ii, metadata in data.metadata.iterrows():\n",
    "    if range_ii[0] < ii <= range_ii[1]:\n",
    "        # print(metadata)\n",
    "        fig = plt.figure(figsize=(7, 2.5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        trace = data.get_waveforms(ii)\n",
    "        print(trace.shape)\n",
    "        ax.plot(trace.T, lw=0.3)\n",
    "        targets = [key for key in metadata.keys() if 'arrival' in key]\n",
    "        targets = [key for key in targets if not np.isnan(metadata[key])]\n",
    "        # print(targets, metadata[targets])\n",
    "        for target in targets:\n",
    "            phase_hint = target.split('_')[2]\n",
    "            ax.axvline(metadata[target], lw=3, c=cmap(phase_hint), label=phase_hint)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71929390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "for key, val in phase_dict.items():\n",
    "    tmp[key.replace('trace', 'trace_manual')] = val\n",
    "\n",
    "phase_dict = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench.generate as sbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be298b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sbg.GenericGenerator(data)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.WindowAroundSample(list(phase_dict.keys()), samples_before=3000, windowlen=6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict, sigma=30, dim=0)\n",
    "]\n",
    "\n",
    "generator.add_augmentations(augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "class Tapering:\n",
    "    def __init__(self, alpha=0.3, key='X'):\n",
    "        self.alpha = alpha  # ضریب تیپرینگ\n",
    "        if isinstance(key, str):\n",
    "            self.key = (key, key)\n",
    "        else:\n",
    "            self.key = key\n",
    "\n",
    "    def __call__(self, state_dict):\n",
    "        x, metadata = state_dict[self.key[0]]\n",
    "        taper = signal.windows.tukey(x.shape[-1], self.alpha)\n",
    "        x = x * taper\n",
    "        state_dict[self.key[1]] = (x, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sbg.GenericGenerator(data)\n",
    "\n",
    "augmentations = [\n",
    "    Tapering(),\n",
    "    # sbg.WindowAroundSample(metadata_keys=list(phase_dict.keys()), samples_before=6000, windowlen=2*6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=2*3001, strategy=\"pad\"),\n",
    "    sbg.GaussianNoise(scale=(0.01, 0.02), key='X'),\n",
    "    # sbg.RealNoise(noise_dataset, scale=(0, 1), scaling_type='peak', metadata_thresholds=None, key='X'),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict, sigma=30, dim=0)\n",
    "]\n",
    "\n",
    "generator.add_augmentations(augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generator(n=None):\n",
    "    if n is None:\n",
    "        n = np.random.randint(len(generator))\n",
    "    print(f'{n=}')\n",
    "    print(data.metadata.iloc[n])\n",
    "    sample = generator[n]\n",
    "    fig, axs = plt.subplots(2, 1, sharex=True, figsize=(15, 5),\n",
    "                            gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "    axs[0].plot(sample[\"X\"].T)\n",
    "    axs[1].plot(sample[\"y\"].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generator(n=3347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbf035",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generator(n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01477248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generator(n=15229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede84a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generator(n=15351)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2930fb",
   "metadata": {
    "id": "1c2930fb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Considerations for converting datasets\n",
    "\n",
    "As outlined above, this tutorial provides a very minimal example on converting a dataset. Here we outline additional consideration that should be taken into account when preparing a dataset.\n",
    "\n",
    "- **Grouping picks**: In this example, we created one trace for each pick. Naturally, traces will overlap if multiple picks, e.g., P and S phases, are available for an event at a station. For an example implementation of this grouping operation, have a look [here](https://github.com/seisbench/seisbench/blob/df94dcd86ce66d6a2ee2bd00da3857259fe579bd/seisbench/data/ethz.py#L109) and in the subsequent lines.\n",
    "- **Adding station information**: In this example, we added no station information except its name. In practice, it will often be helpful for users to incorporate, for example, the location of the station. We skipped this step here, because it requires loading station inventories through FDSN. For an example implementation, have a look [here](https://github.com/seisbench/seisbench/blob/df94dcd86ce66d6a2ee2bd00da3857259fe579bd/seisbench/data/ethz.py#L315).\n",
    "- **Memory requirements**: Internally, the `WaveformDataWriter` writes out the the waveforms continuously in blocks (see point below), but keeps all metadata in memory until the dataset is complete. For very large datasets (or very detailed metadata) this can result in several gigabytes of memory consumption. If you are writing such datasets, make sure the available memory on your machine is sufficient.\n",
    "- **Waveform blocks**: Instead of writing each waveform separately, waveforms are written out in blocks. This massively improves IO performance. Have a look at [the documentation](https://seisbench.readthedocs.io/en/stable/pages/data_format.html#traces-blocks) for details on the strategy. We expect that in nearly all cases using the default setting will be a good choice.\n",
    "- **FDSN considerations**: When converting very large datasets, the performance might be limited by the performance of the FDSN webservice. Unfortunately, downloading lots of short waveforms (as required for many machine learning applications) does not seem to be the most favorable use case for FDSN. This leads to rather slow performance when naively downloading the waveforms as outlined above. Instead, it is often helpful to issue [bulk requests](https://docs.obspy.org/master/packages/autogen/obspy.clients.fdsn.client.Client.get_waveforms_bulk.html). In addition, it might be a good choice to first download the waveforms and cache them locally, for example, in .mseed format, and then convert them to SeisBench.\n",
    "\n",
    "For further details on the data format, check out [the data format specification in the SeisBench documentation](https://seisbench.readthedocs.io/en/stable/pages/data_format.html#traces-blocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbde789",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 4\n",
    "metadata = data.metadata.iloc[ii]\n",
    "# print(metadata)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 5), sharex=True)\n",
    "trace = data.get_waveforms(ii)\n",
    "print(trace.shape)\n",
    "for jj in range(3):\n",
    "    axes[jj].plot(trace.T[:, jj], c='k', lw=0.5)\n",
    "    axes[jj].patch.set_visible(False)\n",
    "    axes[jj].axis('off')\n",
    "targets = [key for key in metadata.keys() if 'arrival' in key]\n",
    "targets = [key for key in targets if not np.isnan(metadata[key])]\n",
    "# print(targets, metadata[targets])\n",
    "for target in targets:\n",
    "    phase_hint = target.split('_')[1]\n",
    "    for jj in range(3):\n",
    "        axes[jj].axvline(metadata[target], lw=2, c=cmap(phase_hint), label=phase_hint[0])\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a87d85",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tapering:\n",
    "    def __init__(self, alpha=0.2, key='X'):\n",
    "        self.alpha = alpha  # ضریب تیپرینگ\n",
    "        if isinstance(key, str):\n",
    "            self.key = (key, key)\n",
    "        else:\n",
    "            self.key = key\n",
    "\n",
    "    def __call__(self, state_dict):\n",
    "        x, metadata = state_dict[self.key[0]]\n",
    "        taper = signal.windows.tukey(x.shape[-1], self.alpha)\n",
    "        x = x * taper\n",
    "        state_dict[self.key[1]] = (x, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict,\n",
    "                              model_labels=cfg.model.phases,\n",
    "                              sigma=30, dim=0),    \n",
    "]\n",
    "\n",
    "generator = sbg.GenericGenerator(data.train())\n",
    "generator.add_augmentations(augmentations)\n",
    "\n",
    "\n",
    "sample_number = 1124 #np.random.randint(len(generator))\n",
    "sample = generator[sample_number]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "axs[0].plot(sample[\"X\"].T)\n",
    "axs[1].plot(sample[\"y\"].T)\n",
    "plt.suptitle(sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3976308",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    Tapering(),\n",
    "    sbg.FixedWindow(p0=-35*100, windowlen=2*3000, strategy=\"pad\", key='X'),\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    # sbg.GaussianNoise(scale=(0, 0.002), key='X'),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict,\n",
    "                              model_labels=cfg.model.phases,\n",
    "                              sigma=30, dim=0),    \n",
    "]\n",
    "\n",
    "train = data.train()\n",
    "generator = sbg.GenericGenerator(train)\n",
    "generator.add_augmentations(augmentations)\n",
    "\n",
    "\n",
    "sample_number = 432#np.random.randint(len(generator))\n",
    "sample = generator[sample_number]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "axs[0].plot(sample[\"X\"].T)\n",
    "axs[1].plot(sample[\"y\"].T)\n",
    "plt.suptitle(sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    Tapering(),\n",
    "    sbg.FixedWindow(p0=-35*100, windowlen=2*3000, strategy=\"pad\", key='X'),\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    # sbg.GaussianNoise(scale=(0, 0.002), key='X'),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict,\n",
    "                              model_labels=cfg.model.phases,\n",
    "                              sigma=30, dim=0),    \n",
    "]\n",
    "\n",
    "train = data.train()\n",
    "generator = sbg.GenericGenerator(train)\n",
    "generator.add_augmentations(augmentations)\n",
    "\n",
    "\n",
    "sample_number = 432#np.random.randint(len(generator))\n",
    "sample = generator[sample_number]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "axs[0].plot(sample[\"X\"].T)\n",
    "axs[1].plot(sample[\"y\"].T)\n",
    "plt.suptitle(sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a848f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902cab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
